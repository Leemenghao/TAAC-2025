from pathlib import Path
import copy
import random

import numpy as np
import torch
import torch.nn.functional as F
from tqdm import tqdm

from dataset import save_emb


class FlashMultiHeadAttention(torch.nn.Module):
    def __init__(self, hidden_units, num_heads, dropout_rate):
        super(FlashMultiHeadAttention, self).__init__()

        self.hidden_units = hidden_units
        self.num_heads = num_heads
        self.head_dim = hidden_units // num_heads
        self.dropout_rate = dropout_rate

        assert hidden_units % num_heads == 0, "hidden_units must be divisible by num_heads"

        self.q_linear = torch.nn.Linear(hidden_units, hidden_units)
        self.k_linear = torch.nn.Linear(hidden_units, hidden_units)
        self.v_linear = torch.nn.Linear(hidden_units, hidden_units)
        self.out_linear = torch.nn.Linear(hidden_units, hidden_units)

    def forward(self, query, key, value, attn_mask=None):
        batch_size, seq_len, _ = query.size()

        # è®¡ç®—Q, K, V
        Q = self.q_linear(query)
        K = self.k_linear(key)
        V = self.v_linear(value)

        # reshapeä¸ºmulti-headæ ¼å¼
        Q = Q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)
        K = K.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)
        V = V.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)

        if hasattr(F, 'scaled_dot_product_attention'):
            # PyTorch 2.0+ ä½¿ç”¨å†…ç½®çš„Flash Attention
            attn_output = F.scaled_dot_product_attention(
                Q, K, V, dropout_p=self.dropout_rate if self.training else 0.0, attn_mask=attn_mask.unsqueeze(1)
            )
        else:
            # é™çº§åˆ°æ ‡å‡†æ³¨æ„åŠ›æœºåˆ¶
            scale = (self.head_dim) ** -0.5
            scores = torch.matmul(Q, K.transpose(-2, -1)) * scale

            if attn_mask is not None:
                scores.masked_fill_(attn_mask.unsqueeze(1).logical_not(), float('-inf'))

            attn_weights = F.softmax(scores, dim=-1)
            attn_weights = F.dropout(attn_weights, p=self.dropout_rate, training=self.training)
            attn_output = torch.matmul(attn_weights, V)

        # reshapeå›åŸæ¥çš„æ ¼å¼
        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_units)

        # æœ€ç»ˆçš„çº¿æ€§å˜æ¢
        output = self.out_linear(attn_output)

        return output, None


class PointWiseFeedForward(torch.nn.Module):
    def __init__(self, hidden_units, dropout_rate):
        super(PointWiseFeedForward, self).__init__()

        self.conv1 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)
        self.dropout1 = torch.nn.Dropout(p=dropout_rate)
        self.relu = torch.nn.ReLU()
        self.conv2 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)
        self.dropout2 = torch.nn.Dropout(p=dropout_rate)

    def forward(self, inputs):
        outputs = self.dropout2(self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))
        outputs = outputs.transpose(-1, -2)  # as Conv1D requires (N, C, Length)
        return outputs


class BaselineModel(torch.nn.Module):
    """
    Args:
        user_num: ç”¨æˆ·æ•°é‡
        item_num: ç‰©å“æ•°é‡
        feat_statistics: ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯ï¼Œkeyä¸ºç‰¹å¾IDï¼Œvalueä¸ºç‰¹å¾æ•°é‡
        feat_types: å„ä¸ªç‰¹å¾çš„ç‰¹å¾ç±»å‹ï¼Œkeyä¸ºç‰¹å¾ç±»å‹åç§°ï¼Œvalueä¸ºåŒ…å«çš„ç‰¹å¾IDåˆ—è¡¨ï¼ŒåŒ…æ‹¬userå’Œitemçš„sparse, array, emb, continualç±»å‹
        args: å…¨å±€å‚æ•°

    Attributes:
        user_num: ç”¨æˆ·æ•°é‡
        item_num: ç‰©å“æ•°é‡
        dev: è®¾å¤‡
        norm_first: æ˜¯å¦å…ˆå½’ä¸€åŒ–
        maxlen: åºåˆ—æœ€å¤§é•¿åº¦
        item_emb: Item Embedding Table
        user_emb: User Embedding Table
        sparse_emb: ç¨€ç–ç‰¹å¾Embedding Table
        emb_transform: å¤šæ¨¡æ€ç‰¹å¾çš„çº¿æ€§å˜æ¢
        userdnn: ç”¨æˆ·ç‰¹å¾æ‹¼æ¥åç»è¿‡çš„å…¨è¿æ¥å±‚
        itemdnn: ç‰©å“ç‰¹å¾æ‹¼æ¥åç»è¿‡çš„å…¨è¿æ¥å±‚
    """

    def __init__(self, user_num, item_num, feat_statistics, feat_types, args, writer):  #
        super(BaselineModel, self).__init__()

        self.user_num = user_num
        self.item_num = item_num
        self.dev = args.device
        self.norm_first = args.norm_first
        self.maxlen = args.maxlen
        self.temperature = args.temperature
        self.mask_ratio = args.mask_ratio
        self.writer = writer
        # TODO: loss += args.l2_emb for regularizing embedding vectors during training
        # https://stackoverflow.com/questions/42704283/adding-l1-l2-regularization-in-pytorch

        self.item_emb = torch.nn.Embedding(self.item_num + 1, args.hidden_units, padding_idx=0)
        self.user_emb = torch.nn.Embedding(self.user_num + 1, args.hidden_units, padding_idx=0)
        self.pos_emb = torch.nn.Embedding(2 * args.maxlen + 1, args.hidden_units, padding_idx=0)
        self.emb_dropout = torch.nn.Dropout(p=args.dropout_rate)
        self.sparse_emb = torch.nn.ModuleDict()
        self.emb_transform = torch.nn.ModuleDict()

        self.attention_layernorms = torch.nn.ModuleList()  # to be Q for self-attention
        self.attention_layers = torch.nn.ModuleList()
        self.forward_layernorms = torch.nn.ModuleList()
        self.forward_layers = torch.nn.ModuleList()

        self._init_feat_info(feat_statistics, feat_types)

        userdim = args.hidden_units * (len(self.USER_SPARSE_FEAT) + 1 + len(self.USER_ARRAY_FEAT)) + len(
            self.USER_CONTINUAL_FEAT
        )
        itemdim = (
            args.hidden_units * (len(self.ITEM_SPARSE_FEAT) + 1 + len(self.ITEM_ARRAY_FEAT))
            + len(self.ITEM_CONTINUAL_FEAT)
            + args.hidden_units * len(self.ITEM_EMB_FEAT)
        )

        self.userdnn = torch.nn.Linear(userdim, args.hidden_units)
        self.itemdnn = torch.nn.Linear(itemdim, args.hidden_units)

        self.last_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)

        for _ in range(args.num_blocks):
            new_attn_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)
            self.attention_layernorms.append(new_attn_layernorm)

            new_attn_layer = FlashMultiHeadAttention(
                args.hidden_units, args.num_heads, args.dropout_rate
            )  # ä¼˜åŒ–ï¼šç”¨FlashAttentionæ›¿ä»£æ ‡å‡†Attention
            self.attention_layers.append(new_attn_layer)

            new_fwd_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)
            self.forward_layernorms.append(new_fwd_layernorm)

            new_fwd_layer = PointWiseFeedForward(args.hidden_units, args.dropout_rate)
            self.forward_layers.append(new_fwd_layer)

        for k in self.USER_SPARSE_FEAT:
            self.sparse_emb[k] = torch.nn.Embedding(self.USER_SPARSE_FEAT[k] + 1, args.hidden_units, padding_idx=0)
        for k in self.ITEM_SPARSE_FEAT:
            self.sparse_emb[k] = torch.nn.Embedding(self.ITEM_SPARSE_FEAT[k] + 1, args.hidden_units, padding_idx=0)
        for k in self.ITEM_ARRAY_FEAT:
            self.sparse_emb[k] = torch.nn.Embedding(self.ITEM_ARRAY_FEAT[k] + 1, args.hidden_units, padding_idx=0)
        for k in self.USER_ARRAY_FEAT:
            self.sparse_emb[k] = torch.nn.Embedding(self.USER_ARRAY_FEAT[k] + 1, args.hidden_units, padding_idx=0)
        for k in self.ITEM_EMB_FEAT:
            self.emb_transform[k] = torch.nn.Linear(self.ITEM_EMB_FEAT[k], args.hidden_units)

    def _init_feat_info(self, feat_statistics, feat_types):
        """
        å°†ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯ï¼ˆç‰¹å¾æ•°é‡ï¼‰æŒ‰ç‰¹å¾ç±»å‹åˆ†ç»„äº§ç”Ÿä¸åŒçš„å­—å…¸ï¼Œæ–¹ä¾¿å£°æ˜ç¨€ç–ç‰¹å¾çš„Embedding Table

        Args:
            feat_statistics: ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯ï¼Œkeyä¸ºç‰¹å¾IDï¼Œvalueä¸ºç‰¹å¾æ•°é‡
            feat_types: å„ä¸ªç‰¹å¾çš„ç‰¹å¾ç±»å‹ï¼Œkeyä¸ºç‰¹å¾ç±»å‹åç§°ï¼Œvalueä¸ºåŒ…å«çš„ç‰¹å¾IDåˆ—è¡¨ï¼ŒåŒ…æ‹¬userå’Œitemçš„sparse, array, emb, continualç±»å‹
        """
        self.USER_SPARSE_FEAT = {k: feat_statistics[k] for k in feat_types['user_sparse']}
        self.USER_CONTINUAL_FEAT = feat_types['user_continual']
        self.ITEM_SPARSE_FEAT = {k: feat_statistics[k] for k in feat_types['item_sparse']}
        self.ITEM_CONTINUAL_FEAT = feat_types['item_continual']
        self.USER_ARRAY_FEAT = {k: feat_statistics[k] for k in feat_types['user_array']}
        self.ITEM_ARRAY_FEAT = {k: feat_statistics[k] for k in feat_types['item_array']}
        EMB_SHAPE_DICT = {"81": 32, "82": 1024, "83": 3584, "84": 4096, "85": 3584, "86": 3584}
        self.ITEM_EMB_FEAT = {k: EMB_SHAPE_DICT[k] for k in feat_types['item_emb']}  # è®°å½•çš„æ˜¯ä¸åŒå¤šæ¨¡æ€ç‰¹å¾çš„ç»´åº¦

    def feat2tensor(self, seq_feature, k):
        """
        Args:
            seq_feature: åºåˆ—ç‰¹å¾listï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå½“å‰æ—¶åˆ»çš„ç‰¹å¾å­—å…¸ï¼Œå½¢çŠ¶ä¸º [batch_size, maxlen]
            k: ç‰¹å¾ID

        Returns:
            batch_data: ç‰¹å¾å€¼çš„tensorï¼Œå½¢çŠ¶ä¸º [batch_size, maxlen, max_array_len(if array)]
        """
        batch_size = len(seq_feature)

        if k in self.ITEM_ARRAY_FEAT or k in self.USER_ARRAY_FEAT:
            # å¦‚æœç‰¹å¾æ˜¯Arrayç±»å‹ï¼Œéœ€è¦å…ˆå¯¹arrayè¿›è¡Œpaddingï¼Œç„¶åè½¬æ¢ä¸ºtensor
            max_array_len = 0
            max_seq_len = 0

            for i in range(batch_size):
                seq_data = [item[k] for item in seq_feature[i]]
                max_seq_len = max(max_seq_len, len(seq_data))
                max_array_len = max(max_array_len, max(len(item_data) for item_data in seq_data))

            batch_data = np.zeros((batch_size, max_seq_len, max_array_len), dtype=np.int64)
            for i in range(batch_size):
                seq_data = [item[k] for item in seq_feature[i]]
                for j, item_data in enumerate(seq_data):
                    actual_len = min(len(item_data), max_array_len)
                    batch_data[i, j, :actual_len] = item_data[:actual_len]

            return torch.from_numpy(batch_data).to(self.dev)
        else:
            # å¦‚æœç‰¹å¾æ˜¯Sparseç±»å‹ï¼Œç›´æ¥è½¬æ¢ä¸ºtensor
            max_seq_len = max(len(seq_feature[i]) for i in range(batch_size))
            batch_data = np.zeros((batch_size, max_seq_len), dtype=np.int64)

            for i in range(batch_size):
                seq_data = [item[k] for item in seq_feature[i]]
                batch_data[i] = seq_data

            return torch.from_numpy(batch_data).to(self.dev)

    def feat2emb(self, seq, feature_array, mask=None, include_user=False):
        """
        Args:
            seq: åºåˆ—ID
            feature_array: ç‰¹å¾listï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå½“å‰æ—¶åˆ»çš„ç‰¹å¾å­—å…¸
            mask: æ©ç ï¼Œ1è¡¨ç¤ºitemï¼Œ2è¡¨ç¤ºuser
            include_user: æ˜¯å¦å¤„ç†ç”¨æˆ·ç‰¹å¾ï¼Œåœ¨ä¸¤ç§æƒ…å†µä¸‹ä¸æ‰“å¼€ï¼š1) è®­ç»ƒæ—¶åœ¨è½¬æ¢æ­£è´Ÿæ ·æœ¬çš„ç‰¹å¾æ—¶ï¼ˆå› ä¸ºæ­£è´Ÿæ ·æœ¬éƒ½æ˜¯itemï¼‰;2) ç”Ÿæˆå€™é€‰åº“item embeddingæ—¶ã€‚

        Returns:
            seqs_emb: åºåˆ—ç‰¹å¾çš„Embedding
        """
        seq = seq.to(self.dev)
        # pre-compute embedding
        if include_user:
            user_mask = (mask == 2).to(self.dev)
            item_mask = (mask == 1).to(self.dev)
            user_embedding = self.user_emb(user_mask * seq)
            item_embedding = self.item_emb(item_mask * seq)
            item_feat_list = [item_embedding]
            user_feat_list = [user_embedding]
        else:
            item_embedding = self.item_emb(seq)
            item_feat_list = [item_embedding]

        # batch-process all feature types
        all_feat_types = [
            (self.ITEM_SPARSE_FEAT, 'item_sparse', item_feat_list),
            (self.ITEM_ARRAY_FEAT, 'item_array', item_feat_list),
            (self.ITEM_CONTINUAL_FEAT, 'item_continual', item_feat_list),
        ]

        if include_user:
            all_feat_types.extend(
                [
                    (self.USER_SPARSE_FEAT, 'user_sparse', user_feat_list),
                    (self.USER_ARRAY_FEAT, 'user_array', user_feat_list),
                    (self.USER_CONTINUAL_FEAT, 'user_continual', user_feat_list),
                ]
            )

        # batch-process each feature type
        for feat_dict, feat_type, feat_list in all_feat_types:
            if not feat_dict:
                continue

            for k in feat_dict:
                tensor_feature = self.feat2tensor(feature_array, k)

                if feat_type.endswith('sparse'):
                    feat_list.append(self.sparse_emb[k](tensor_feature))
                elif feat_type.endswith('array'):
                    feat_list.append(self.sparse_emb[k](tensor_feature).sum(2))
                elif feat_type.endswith('continual'):
                    feat_list.append(tensor_feature.unsqueeze(2))

        for k in self.ITEM_EMB_FEAT:
            # collect all data to numpy, then batch-convert
            batch_size = len(feature_array)
            emb_dim = self.ITEM_EMB_FEAT[k]
            seq_len = len(feature_array[0])

            # pre-allocate tensor
            batch_emb_data = np.zeros((batch_size, seq_len, emb_dim), dtype=np.float32)

            for i, seq in enumerate(feature_array):
                for j, item in enumerate(seq):
                    if k in item:
                        batch_emb_data[i, j] = item[k]

            # batch-convert and transfer to GPU
            tensor_feature = torch.from_numpy(batch_emb_data).to(self.dev)
            item_feat_list.append(self.emb_transform[k](tensor_feature))

        # merge features
        all_item_emb = torch.cat(item_feat_list, dim=2)
        all_item_emb = torch.relu(self.itemdnn(all_item_emb))
        if include_user:
            all_user_emb = torch.cat(user_feat_list, dim=2)
            all_user_emb = torch.relu(self.userdnn(all_user_emb))
            seqs_emb = all_item_emb + all_user_emb
        else:
            seqs_emb = all_item_emb
        return seqs_emb

    def log2feats(self, log_seqs, mask, seq_feature):
        """
        Args:
            log_seqs: åºåˆ—ID
            mask: tokenç±»å‹æ©ç ï¼Œ1è¡¨ç¤ºitem tokenï¼Œ2è¡¨ç¤ºuser token
            seq_feature: åºåˆ—ç‰¹å¾listï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå½“å‰æ—¶åˆ»çš„ç‰¹å¾å­—å…¸

        Returns:
            seqs_emb: åºåˆ—çš„Embeddingï¼Œå½¢çŠ¶ä¸º [batch_size, maxlen, hidden_units]
        """
        batch_size = log_seqs.shape[0]
        maxlen = log_seqs.shape[1]
        seqs = self.feat2emb(log_seqs, seq_feature, mask=mask, include_user=True)
        seqs *= self.item_emb.embedding_dim**0.5
        poss = torch.arange(1, maxlen + 1, device=self.dev).unsqueeze(0).expand(batch_size, -1).clone()
        poss *= log_seqs != 0
        seqs += self.pos_emb(poss)
        seqs = self.emb_dropout(seqs)

        maxlen = seqs.shape[1]
        ones_matrix = torch.ones((maxlen, maxlen), dtype=torch.bool, device=self.dev)
        attention_mask_tril = torch.tril(ones_matrix)
        attention_mask_pad = (mask != 0).to(self.dev)
        attention_mask = attention_mask_tril.unsqueeze(0) & attention_mask_pad.unsqueeze(1)

        for i in range(len(self.attention_layers)):
            if self.norm_first:
                x = self.attention_layernorms[i](seqs)
                mha_outputs, _ = self.attention_layers[i](x, x, x, attn_mask=attention_mask)
                seqs = seqs + mha_outputs
                seqs = seqs + self.forward_layers[i](self.forward_layernorms[i](seqs))
            else:
                mha_outputs, _ = self.attention_layers[i](seqs, seqs, seqs, attn_mask=attention_mask)
                seqs = self.attention_layernorms[i](seqs + mha_outputs)
                seqs = self.forward_layernorms[i](seqs + self.forward_layers[i](seqs))

        log_feats = self.last_layernorm(seqs)

        return log_feats

    def forward(
        self, user_item, pos_seqs, neg_seqs, mask, next_mask, next_action_type, seq_feature, pos_feature, neg_feature
    ):
        """
        è®­ç»ƒæ—¶è°ƒç”¨ï¼Œè®¡ç®—æ­£è´Ÿæ ·æœ¬çš„logits

        Args:
            user_item: ç”¨æˆ·åºåˆ—ID
            pos_seqs: æ­£æ ·æœ¬åºåˆ—ID
            neg_seqs: è´Ÿæ ·æœ¬åºåˆ—ID
            mask: tokenç±»å‹æ©ç ï¼Œ1è¡¨ç¤ºitem tokenï¼Œ2è¡¨ç¤ºuser token
            next_mask: ä¸‹ä¸€ä¸ªtokenç±»å‹æ©ç ï¼Œ1è¡¨ç¤ºitem tokenï¼Œ2è¡¨ç¤ºuser token
            next_action_type: ä¸‹ä¸€ä¸ªtokenåŠ¨ä½œç±»å‹ï¼Œ0è¡¨ç¤ºæ›å…‰ï¼Œ1è¡¨ç¤ºç‚¹å‡»
            seq_feature: åºåˆ—ç‰¹å¾listï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå½“å‰æ—¶åˆ»çš„ç‰¹å¾å­—å…¸
            pos_feature: æ­£æ ·æœ¬ç‰¹å¾listï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå½“å‰æ—¶åˆ»çš„ç‰¹å¾å­—å…¸
            neg_feature: è´Ÿæ ·æœ¬ç‰¹å¾listï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå½“å‰æ—¶åˆ»çš„ç‰¹å¾å­—å…¸

        Returns:
            pos_logits: æ­£æ ·æœ¬logitsï¼Œå½¢çŠ¶ä¸º [batch_size, maxlen]
            neg_logits: è´Ÿæ ·æœ¬logitsï¼Œå½¢çŠ¶ä¸º [batch_size, maxlen]
        """
        log_feats = self.log2feats(user_item, mask, seq_feature)
        loss_mask = (next_mask == 1).to(self.dev)

        pos_embs = self.feat2emb(pos_seqs, pos_feature, include_user=False)
        neg_embs = self.feat2emb(neg_seqs, neg_feature, include_user=False)

        pos_logits = (log_feats * pos_embs).sum(dim=-1)
        neg_logits = (log_feats * neg_embs).sum(dim=-1)
        pos_logits = pos_logits * loss_mask
        neg_logits = neg_logits * loss_mask

        return pos_logits, neg_logits

    def predict(self, log_seqs, seq_feature, mask):
        """
        è®¡ç®—ç”¨æˆ·åºåˆ—çš„è¡¨å¾
        Args:
            log_seqs: ç”¨æˆ·åºåˆ—ID
            seq_feature: åºåˆ—ç‰¹å¾listï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå½“å‰æ—¶åˆ»çš„ç‰¹å¾å­—å…¸
            mask: tokenç±»å‹æ©ç ï¼Œ1è¡¨ç¤ºitem tokenï¼Œ2è¡¨ç¤ºuser token
        Returns:
            final_feat: ç”¨æˆ·åºåˆ—çš„è¡¨å¾ï¼Œå½¢çŠ¶ä¸º [batch_size, hidden_units]
        """
        log_feats = self.log2feats(log_seqs, mask, seq_feature)

        final_feat = log_feats[:, -1, :]

        return final_feat

    def save_item_emb(self, item_ids, retrieval_ids, feat_dict, save_path, batch_size=1024):
        """
        ç”Ÿæˆå€™é€‰åº“item embeddingï¼Œç”¨äºæ£€ç´¢

        Args:
            item_ids: å€™é€‰item IDï¼ˆre-idå½¢å¼ï¼‰
            retrieval_ids: å€™é€‰item IDï¼ˆæ£€ç´¢IDï¼Œä»0å¼€å§‹ç¼–å·ï¼Œæ£€ç´¢è„šæœ¬ä½¿ç”¨ï¼‰
            feat_dict: è®­ç»ƒé›†æ‰€æœ‰itemç‰¹å¾å­—å…¸ï¼Œkeyä¸ºç‰¹å¾IDï¼Œvalueä¸ºç‰¹å¾å€¼
            save_path: ä¿å­˜è·¯å¾„
            batch_size: æ‰¹æ¬¡å¤§å°
        """
        all_embs = []

        for start_idx in tqdm(range(0, len(item_ids), batch_size), desc="Saving item embeddings"):
            end_idx = min(start_idx + batch_size, len(item_ids))

            item_seq = torch.tensor(item_ids[start_idx:end_idx], device=self.dev).unsqueeze(0)
            batch_feat = []
            for i in range(start_idx, end_idx):
                batch_feat.append(feat_dict[i])

            batch_feat = np.array(batch_feat, dtype=object)

            batch_emb = self.feat2emb(item_seq, [batch_feat], include_user=False).squeeze(0)

            all_embs.append(batch_emb.detach().cpu().numpy().astype(np.float32))

        # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœå¹¶ä¿å­˜
        final_ids = np.array(retrieval_ids, dtype=np.uint64).reshape(-1, 1)
        final_embs = np.concatenate(all_embs, axis=0)
        save_emb(final_embs, Path(save_path, 'embedding.fbin'))
        save_emb(final_ids, Path(save_path, 'id.u64bin'))

    def contrastive_loss(
            self, user_item, pos_seqs, neg_seqs, mask, next_mask, 
            next_action_type, seq_feature, pos_feature, neg_feature,
            aug_neg_feat1, aug_neg_feat2, global_step=None
        ):
        """
        è‡ªç›‘ç£å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œåªè®­ç»ƒç‰©å“å¡”
        
        Args:
            user_item: ç”¨æˆ·åºåˆ—ID
            pos_seqs: æ­£æ ·æœ¬åºåˆ—ID
            neg_seqs: è´Ÿæ ·æœ¬åºåˆ—ID
            mask: tokenç±»å‹æ©ç ï¼Œ1è¡¨ç¤ºitem tokenï¼Œ2è¡¨ç¤ºuser token
            next_mask: ä¸‹ä¸€ä¸ªtokenç±»å‹æ©ç 
            next_action_type: ä¸‹ä¸€ä¸ªtokenåŠ¨ä½œç±»å‹
            seq_feature: åºåˆ—ç‰¹å¾list
            pos_feature: æ­£æ ·æœ¬ç‰¹å¾list
            neg_feature: è´Ÿæ ·æœ¬ç‰¹å¾list
            aug_neg_feat1: ç¬¬ä¸€ä¸ªå¢å¼ºçš„è´Ÿæ ·æœ¬ç‰¹å¾ï¼ˆæ¥è‡ªdatasetï¼‰
            aug_neg_feat2: ç¬¬äºŒä¸ªå¢å¼ºçš„è´Ÿæ ·æœ¬ç‰¹å¾ï¼ˆæ¥è‡ªdatasetï¼‰
            global_step: å…¨å±€æ­¥æ•°ï¼Œç”¨äºè®°å½•åˆ°TensorBoard
            
        Returns:
            loss: å¯¹æ¯”å­¦ä¹ æŸå¤±
        """
        
        # ä½¿ç”¨feat2embè·å–ç‰©å“embeddingï¼Œä¸åŒ…å«ç”¨æˆ·ä¿¡æ¯
        item_embs1 = self.feat2emb(neg_seqs, aug_neg_feat1, include_user=False)  # [B, L, hidden_units]
        item_embs2 = self.feat2emb(neg_seqs, aug_neg_feat2, include_user=False)  # [B, L, hidden_units]
        
        # L2å½’ä¸€åŒ–
        item_embs1 = F.normalize(item_embs1, dim=-1)
        item_embs2 = F.normalize(item_embs2, dim=-1)

        # åˆ›å»ºitem maskï¼Œåªä¿ç•™æœ‰æ•ˆçš„itemä½ç½®
        loss_mask = (mask == 1).to(self.dev)  # [batch_size, maxlen]
        
        # åªä¿ç•™æœ‰æ•ˆitemä½ç½®çš„embedding,
        valid_embs1 = item_embs1[loss_mask]  # [B, mask_len, hidden_units]
        valid_embs2 = item_embs2[loss_mask]  # [B, mask_len, hidden_units]

        # å°†embedding reshapeä¸ºäºŒç»´ï¼Œæ–¹ä¾¿è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        hidden_size = valid_embs1.size(-1)
        valid_embs1 = valid_embs1.reshape(-1, hidden_size)  # [B * L, hidden_size]
        valid_embs2 = valid_embs2.reshape(-1, hidden_size)  # [B * L, hidden_size]

        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µï¼švalid_embs1 @ valid_embs2.T
        similarity_matrix = torch.matmul(valid_embs1, valid_embs2.T) / self.temperature  # [B * L, B * L]
        
        # åˆ›å»ºæ ‡ç­¾ï¼šå¯¹è§’çº¿ä½ç½®ä¸º1ï¼ˆåŒä¸€ä½ç½®çš„itemä¸ºæ­£æ ·æœ¬ï¼‰ï¼Œå…¶ä½™ä¸º0
        num_valid_items = valid_embs1.shape[0]
        labels = torch.arange(num_valid_items, device=self.dev)  # [0, 1, 2, ..., num_valid_items-1]
        
        # ğŸ“Š è®°å½•ç›¸ä¼¼åº¦ç»Ÿè®¡ä¿¡æ¯åˆ°TensorBoard
        if self.writer and global_step is not None:
            with torch.no_grad():
                # 1. å¯¹è§’çº¿ç›¸ä¼¼åº¦ï¼ˆæ­£æ ·æœ¬å¯¹ï¼‰
                diagonal_sim = torch.diag(similarity_matrix)
                self.writer.add_scalar('SSL/positive_similarity_mean', diagonal_sim.mean().item(), global_step)
                self.writer.add_scalar('SSL/positive_similarity_std', diagonal_sim.std().item(), global_step)
                self.writer.add_scalar('SSL/positive_similarity_min', diagonal_sim.min().item(), global_step)
                self.writer.add_scalar('SSL/positive_similarity_max', diagonal_sim.max().item(), global_step)
                
                # 2. éå¯¹è§’çº¿ç›¸ä¼¼åº¦ï¼ˆè´Ÿæ ·æœ¬å¯¹ï¼‰
                mask_diag = ~torch.eye(similarity_matrix.size(0), dtype=torch.bool, device=self.dev)
                off_diagonal_sim = similarity_matrix[mask_diag]
                self.writer.add_scalar('SSL/negative_similarity_mean', off_diagonal_sim.mean().item(), global_step)
                self.writer.add_scalar('SSL/negative_similarity_std', off_diagonal_sim.std().item(), global_step)
                
                # 3. æ­£è´Ÿæ ·æœ¬ç›¸ä¼¼åº¦å·®å¼‚
                pos_neg_gap = diagonal_sim.mean() - off_diagonal_sim.mean()
                self.writer.add_scalar('SSL/pos_neg_similarity_gap', pos_neg_gap.item(), global_step)
                
                # 4. ç›¸ä¼¼åº¦åˆ†å¸ƒç›´æ–¹å›¾
                self.writer.add_histogram('SSL/positive_similarities', diagonal_sim, global_step)
                self.writer.add_histogram('SSL/negative_similarities', off_diagonal_sim, global_step)
                
                # 5. æ¸©åº¦ç¼©æ”¾å‰çš„åŸå§‹ç›¸ä¼¼åº¦
                raw_similarity = similarity_matrix * self.temperature
                raw_diagonal = torch.diag(raw_similarity)
                self.writer.add_scalar('SSL/raw_positive_similarity_mean', raw_diagonal.mean().item(), global_step)

        # è®¡ç®—äº¤å‰ç†µæŸå¤±
        loss = F.cross_entropy(similarity_matrix, labels)
        
        # è®°å½•æŸå¤±
        if self.writer and global_step is not None:
            self.writer.add_scalar('SSL/contrastive_loss', loss.item(), global_step)
        
        return loss.mean()

    def ssl_forward(
            self, user_item, pos_seqs, neg_seqs, mask, next_mask, 
            next_action_type, seq_feature, pos_feature, neg_feature,
            aug_neg_feat1, aug_neg_feat2, global_step=None
        ):
        """
        è‡ªç›‘ç£è®­ç»ƒå‰å‘ä¼ æ’­
        
        Args:
            user_item: ç”¨æˆ·åºåˆ—ID
            pos_seqs: æ­£æ ·æœ¬åºåˆ—ID  
            neg_seqs: è´Ÿæ ·æœ¬åºåˆ—ID
            mask: tokenç±»å‹æ©ç ï¼Œ1è¡¨ç¤ºitem tokenï¼Œ2è¡¨ç¤ºuser token
            next_mask: ä¸‹ä¸€ä¸ªtokenç±»å‹æ©ç 
            next_action_type: ä¸‹ä¸€ä¸ªtokenåŠ¨ä½œç±»å‹
            seq_feature: åºåˆ—ç‰¹å¾list
            pos_feature: æ­£æ ·æœ¬ç‰¹å¾list
            neg_feature: è´Ÿæ ·æœ¬ç‰¹å¾list
            aug_neg_feat1: ç¬¬ä¸€ä¸ªå¢å¼ºçš„è´Ÿæ ·æœ¬ç‰¹å¾
            aug_neg_feat2: ç¬¬äºŒä¸ªå¢å¼ºçš„è´Ÿæ ·æœ¬ç‰¹å¾
            global_step: å…¨å±€æ­¥æ•°ï¼Œç”¨äºè®°å½•åˆ°TensorBoard
            
        Returns:
            ssl_loss: è‡ªç›‘ç£å­¦ä¹ æŸå¤±
        """
        
        return self.contrastive_loss(
            user_item, pos_seqs, neg_seqs, mask, next_mask, next_action_type, 
            seq_feature, pos_feature, neg_feature, aug_neg_feat1, aug_neg_feat2, global_step
        )
